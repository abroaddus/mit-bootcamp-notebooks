{"cells":[{"cell_type":"markdown","metadata":{"id":"q7EiMOg9SPQe"},"source":["-----------------------------\n","## Practice Hands-on case study: Linear Regression\n","\n","-----------------------------\n","\n","Welcome to the Hands-on case study on Linear Regression. In this case study, we aim to construct a linear model that explains the relationship a car's mileage (mpg) has with its other attributes\n","\n","-----------------------------\n","## Dataset:\n","-----------------------------\n","There are 8 variables in the data:\n","\n","- mpg: miles per gallon\n","- cyl: number of cylinders\n","- disp: engine displacement (cu. inches) or engine size\n","- hp: horsepower\n","- wt: vehicle weight (lbs.)\n","- acc: time taken to accelerate from O to 60 mph (sec.)\n","- yr: model year\n","- car name: car model name\n","\n","\n","- Also provided are the car labels (types)\n","- Missing data values are marked by series of question marks."]},{"cell_type":"markdown","metadata":{"id":"DKIEGppWSPQt"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"3qeeka95SPQ0","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"error","timestamp":1709170903753,"user_tz":480,"elapsed":166,"user":{"displayName":"Andrea Broaddus","userId":"04235483784400740971"}},"outputId":"8c4b1740-72d9-4fdf-8120-9b7079dca434"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-9-8b993fa5a91d>, line 7)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-8b993fa5a91d>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    from google.colab import drivedrive.mount('/content/drive', force_remount=True)\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","\n","from google.colab import drivedrive.mount('/content/drive', force_remount=True)\n","import os"]},{"cell_type":"code","source":["\n","# the base Google Drive directory\n","root_dir = \"/content/drive/My Drive/\"\n","\n","# choose where you want your project files to be saved\n","project_folder = \"Colab Notebooks/My Project Folder/\"\n","\n","def create_and_set_working_directory(project_folder):\n","  # check if your project folder exists. if not, it will be created.\n","  if os.path.isdir(root_dir + project_folder) == False:\n","    os.mkdir(root_dir + project_folder)\n","    print(root_dir + project_folder + ' did not exist but was created.')\n","\n","  # change the OS to use your project folder as the working directory\n","  os.chdir(root_dir + project_folder)"],"metadata":{"id":"H_PJOcpuhAun"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"atMYrFPnSPQ3"},"source":["## Load and review data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"voLeIc4KSPQ4","outputId":"362bae64-1462-4a02-941f-d0b266695ea6","executionInfo":{"status":"error","timestamp":1709170587701,"user_tz":480,"elapsed":5,"user":{"displayName":"Andrea Broaddus","userId":"04235483784400740971"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'auto_mpg.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-7d12c9da9735>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_mpg.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'auto_mpg.csv'"]}],"source":["data = pd.read_csv(\"auto_mpg.csv\")\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ianp5IpzSPQ9"},"outputs":[],"source":["data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5j9Lbth6SPQ-"},"outputs":[],"source":["#dropping/ignoring car_name\n","data = data.drop('car name', axis=1)\n","# Also replacing the categorical var with actual values\n","data['origin'] = data['origin'].replace({1: 'america', 2: 'europe', 3: 'asia'})\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"jT8CnIuvSPRE"},"source":["## Create Dummy Variables\n","Values like 'america' cannot be read into an equation. Using substitutes like 1 for america, 2 for europe and 3 for asia would end up implying that european cars fall exactly half way between american and asian cars! we dont want to impose such an baseless assumption!\n","\n","So we create 3 simple true or false columns with titles equivalent to \"Is this car America?\", \"Is this care European?\" and \"Is this car Asian?\". These will be used as independent variables without imposing any kind of ordering between the three regions.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a74jWD6dSPRM"},"outputs":[],"source":["data = pd.get_dummies(data, columns=['origin'])\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"HxJtlkfSSPRO"},"source":["## Dealing with Missing Values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ACChlAMCSPRV"},"outputs":[],"source":["#A quick summary of the data columns\n","data.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2l4Z5zpSPRW"},"outputs":[],"source":["# hp is missing cause it does not seem to be reqcognized as a numerical column!\n","data.dtypes"]},{"cell_type":"markdown","metadata":{"id":"--In954HmLka"},"source":["### Q.2 The method  used to check whether an entry of a column is a numerical value or is it missing?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDUyeDg3SPRX"},"outputs":[],"source":[" # if the string is made of digits store True else False hint: use isdigit()\n","hpIsDigit = pd.DataFrame(data.horsepower.str._________())\n","\n","\n","data[hpIsDigit['horsepower'] == False]   # from temp take only those rows where hp has false\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WcDW6u1OSPRY"},"outputs":[],"source":["# Missing values have a'?''\n","# Replace missing values with NaN\n","data = data.replace('?', np.nan)\n","data[hpIsDigit['horsepower'] == False]"]},{"cell_type":"markdown","metadata":{"id":"1ag-N7rRSPRZ"},"source":["There are various ways to handle missing values. Drop the rows, replace missing values with median values etc. of the 398 rows 6 have NAN in the hp column. We could drop those 6 rows - which might not be a good idea under all situations\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqjJ5oslSPRi"},"outputs":[],"source":["#instead of dropping the rows, lets replace the missing values with median value.\n","data.median()"]},{"cell_type":"markdown","metadata":{"id":"iA_DbY64O45T"},"source":["### Filling the missing values with median value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bvz6mToVSPRn"},"outputs":[],"source":["# replace the missing values with median value.\n","# Note, we do not need to specify the column names below\n","# every column's missing value is replaced with that column's median respectively  (axis =0 means columnwise)\n","\n","medianFiller = lambda x: x.fillna(x.median())\n","data = data.apply(medianFiller,axis=0)\n","\n","\n","\n","data['horsepower'] = data['horsepower'].astype('float64')  # converting the hp column from object / string type to float\n"]},{"cell_type":"markdown","metadata":{"id":"62BHlBJnSPRo"},"source":["## BiVariate Plots\n","\n","A bivariate analysis among the different variables can be done using scatter matrix plot. Seaborn libs create a dashboard reflecting useful information about the dimensions. The result can be stored as a .png file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIn_rfG4SPRo"},"outputs":[],"source":["data_attr = data.iloc[:, 0:7]\n","sns.pairplot(data_attr, diag_kind='kde')   # to plot density curve instead of histogram on the diag"]},{"cell_type":"markdown","metadata":{"id":"KNgJgjjgSPRp"},"source":["Observation between 'mpg' and other attributes indicate the relationship is not really linear. However, the plots also indicate that linearity would still capture quite a bit of useful information/pattern. Several assumptions of classical linear regression seem to be violated, including the assumption of no Heteroscedasticity\n"]},{"cell_type":"markdown","metadata":{"id":"U5cmWfIHSPRp"},"source":["## Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oxaq9JIpSPRp"},"outputs":[],"source":["# lets build our linear model\n","# independant variables\n","X = data.drop(columns = {'mpg','origin_europe'})\n","# the dependent variable\n","y = data['mpg']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"06HexPzuSPRq"},"outputs":[],"source":["# Sklearn package's model_selection have a function train_test_split() is used for data splitting into test(out of sample) and train dataset\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Split X and y into training and test set(out of sample data) in 70:30 ratio\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"]},{"cell_type":"markdown","metadata":{"id":"jVK7idYaSPRr"},"source":["### Q.3 & 4 Create linear regression model using statsmodels OLS and interpretate coefficient"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKiG23rLSPRr"},"outputs":[],"source":["# import libraries for building linear regression model\n","#using statsmodel\n","\n","from statsmodels.graphics.gofplots import ProbPlot\n","from statsmodels.formula.api import ols\n","import statsmodels.api as sm\n","\n","# let's add the intercept to data\n","X_train_ols = sm.add_constant(X_train)\n","X_test_ols=sm.add_constant(X_test)\n","\n","# create the model\n","\n","#remove ________ and define ols model and complete the code\n","model1 = ___________________\n","\n","# get the model summary\n","#remove ________ and print summary and complete the code.\n","model1.__________"]},{"cell_type":"markdown","metadata":{"id":"Ej--aPJRixHs"},"source":["- Not all the variables are statistically significant to predict the outcome variable. To check which are statistically significant or have predictive power to predict the target variable, we need to check the `p-value` against all the independent variables.\n","- **Interpreting the Regression Results:**\n","\n","1. **Adjusted. R-squared**: It reflects the fit of the model.\n","    - R-squared values range from 0 to 1, where a higher value generally indicates a better fit, assuming certain conditions are met.\n","    \n","2. **coeff**: It represents the change in the output Y due to a change of one unit in the variable (everything else held constant).\n","3. **std err**: It reflects the level of accuracy of the coefficients.\n","    - The lower it is, the more accurate the coefficients are.\n","4. **P >|t|**: It is p-value.\n","   \n","   * Pr(>|t|) : For each independent feature there is a null hypothesis and alternate hypothesis\n","\n","    Ho : Independent feature is not significant\n","   \n","    Ha : Independent feature is significant\n","    \n","   * A p-value of less than 0.05 is considered to be statistically significant.\n","\n","   \n","5. **Confidence Interval**: It represents the range in which our coefficients are likely to fall (with a likelihood of 95%).\n","\n","* To be able to make statistical inferences from our model, **we will have to test the significance of the regression coefficients and linear regression assumptions.**"]},{"cell_type":"markdown","metadata":{"id":"VATZUe_ElPOY"},"source":["### Checking the performance of the model on the train and test data set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyAboiLolRJN"},"outputs":[],"source":["# RMSE\n","def rmse(predictions, targets):\n","    return np.sqrt(((targets - predictions) ** 2).mean())\n","\n","\n","# MAPE\n","def mape(predictions, targets):\n","    return np.mean(np.abs((targets - predictions)) / targets) * 100\n","\n","\n","# MAE\n","def mae(predictions, targets):\n","    return np.mean(np.abs((targets - predictions)))\n","\n","\n","# Model Performance on test and train data\n","def model_pref(olsmodel, x_train, x_test, y_train,y_test):\n","\n","    # Insample Prediction\n","    y_pred_train = olsmodel.predict(x_train)\n","    y_observed_train = y_train\n","\n","    # Prediction on test data\n","    y_pred_test = olsmodel.predict(x_test)\n","    y_observed_test = y_test\n","\n","    print(\n","        pd.DataFrame(\n","            {\n","                \"Data\": [\"Train\", \"Test\"],\n","                \"RMSE\": [\n","                    rmse(y_pred_train, y_observed_train),\n","                    rmse(y_pred_test, y_observed_test),\n","                ],\n","                \"MAE\": [\n","                    mae(y_pred_train, y_observed_train),\n","                    mae(y_pred_test, y_observed_test),\n","                ],\n","                \"MAPE\": [\n","                    mape(y_pred_train, y_observed_train),\n","                    mape(y_pred_test, y_observed_test),\n","                ],\n","            }\n","        )\n","    )\n","\n","\n","# Checking model performance\n","model_pref(model1, X_train_ols, X_test_ols,y_train,y_test)"]},{"cell_type":"markdown","metadata":{"id":"uSW-478RZmbs"},"source":["**Observations:**\n","\n","* RMSE, MAE, and MAPE of train and test data are not very different, indicating that the **model is not overfitting and has generalized well.**"]},{"cell_type":"markdown","metadata":{"id":"13woqdFRgWT_"},"source":["### Question 5: Performing cross validation and comparing its average performance to OLS performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZD7kWJFyztG"},"outputs":[],"source":["# import the required function\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","\n","# build the regression model using Sklearn Linear regression\n","linearregression = LinearRegression()\n","\n","#remove ________ and cross_val_score and complete the code\n","cv_Score11 = cross_val_score(____________) #cv=10 represents data is divided into 10 folds.\n","cv_Score12 = cross_val_score(____________________,\n","                             scoring = 'neg_mean_squared_error')\n","\n","\n","print(\"RSquared: %0.3f (+/- %0.3f)\" % (cv_Score11.mean(), cv_Score11.std() * 2))\n","print(\"Mean Squared Error: %0.3f (+/- %0.3f)\" % (-1*cv_Score12.mean(), cv_Score12.std() * 2))"]},{"cell_type":"markdown","metadata":{"id":"_e7-DXjiruTC"},"source":["### Get model Coefficients in a pandas dataframe with column 'Feature' having all the features and column 'Coefs' with all the corresponding Coefs. Write the regression equation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-SW4Gt_Drvhb"},"outputs":[],"source":["coef = model1.params\n","coef"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPskalztr6v4"},"outputs":[],"source":["# Let us write the equation of the fit\n","Equation = \"log (car_mileage) =\"\n","print(Equation, end='\\t')\n","for i in range(len(coef)):\n","    print('(', coef[i], ') * ', coef.index[i], '+', end = ' ')"]},{"cell_type":"markdown","metadata":{"id":"VibWka1yzhro"},"source":["### Building Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9-DVRAV0loI"},"outputs":[],"source":["#importing Decision tree regressor using sklearn\n","\n","from sklearn.tree import DecisionTreeRegressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DLvYrCLV0vYf"},"outputs":[],"source":["# splitting the data in 70:30 ratio of train to test data\n","# separate the dependent and indepedent variable\n","Y1 = data['mpg']\n","X1 = data.drop(columns = {'mpg','origin_europe'})\n","X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.30 , random_state=1)"]},{"cell_type":"markdown","metadata":{"id":"usfoMmFdgWUE"},"source":["### Question 6: Building Decision tree and Checking its performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2upb0de1Q-k"},"outputs":[],"source":["#defining the Descision tree regressor\n","#remove ________ and define decision tree and complete the code\n","dt = ________________\n","\n","#Fitting Descision Tree regressor to train dataset\n","#remove ________ and fit decision tree and complete the code\n","dt.fit(______________)"]},{"cell_type":"markdown","metadata":{"id":"DzUyk2761Wzi"},"source":["Checking model perform on the train and test dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hUG7Aj5w1YDC"},"outputs":[],"source":["model_pref(dt, X_train1, X_test1,y_train1,y_test1)"]},{"cell_type":"markdown","metadata":{"id":"hU9tS2bmc5CA"},"source":["**Observations:**\n","\n","- **The model seem to overfit the data** as rmse, mae and mape value of train data is 0, but that value for test data is much higher."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-x6CBJxx6CJm"},"outputs":[],"source":["from sklearn.tree import plot_tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cK89lLf36MVA"},"outputs":[],"source":["features = list(X1.columns)\n","\n","plt.figure(figsize=(35,25))\n","plot_tree(dt, max_depth=4, feature_names=features,filled=True,fontsize=12,node_ids=True,class_names=True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TkKHRdwt6c_K"},"source":["#### Let's plot the feature importance for each variable in the dataset and analyze the variables"]},{"cell_type":"markdown","metadata":{"id":"PTUl-VoGgWUF"},"source":["### Checking Feature importance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VS7lgCU6O3q"},"outputs":[],"source":["#remove ________ and find feature importance decision tree and complete the code\n","\n","importances = dt.______________\n","\n","columns=X1.columns\n","importance_df=pd.DataFrame(importances,index=columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\n","plt.figure(figsize=(8,4))\n","sns.barplot(importance_df.Importance,importance_df.index)"]},{"cell_type":"markdown","metadata":{"id":"sluxW3lpDKft"},"source":["### Building Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"steSpvoTDLwT"},"outputs":[],"source":["#importing random forest regressor usinf sklearn\n","\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"markdown","metadata":{"id":"lbP0IQaxgWUF"},"source":["#### Parameters for regression\n","**n_estimators**: The number of trees in the forest.\n","\n","**min_samples_split**: The minimum number of samples required to split an internal node:\n","\n","**max_depth**\n","The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n","\n","**max_features{“auto”, “sqrt”, “log2”, 'None'}**: The number of features to consider when looking for the best split.\n","\n","- If “auto”, then max_features=sqrt(n_features).\n","\n","- If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n","\n","- If “log2”, then max_features=log2(n_features).\n","\n","- If None, then max_features=n_features."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jj-9yMDZDQNC"},"outputs":[],"source":["#defining the Random forest regressor\n","#remove ________ and define random forest tree and complete the code\n","rf=________________________\n","\n","#Hyperparameters, we have randomly choosen them for now but we can tune these hyperparameters and get the best model.\n","\n","#fitting the model\n","#remove ________ and fit random forest tree and complete the code\n","rf.fit(__________________)"]},{"cell_type":"markdown","metadata":{"id":"Cn-YxjL5NwD1"},"source":["### Q.7 Check performance of Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3CkXaCuDUsG"},"outputs":[],"source":["# checking model performance on test dataset\n","rf.score(__________________)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"96ClBaPuDcqo"},"outputs":[],"source":["model_pref(rf, X_train1, X_test1,y_train1,y_test1)"]},{"cell_type":"markdown","metadata":{"id":"EVvUhEbPgWUG"},"source":["### Question 8 & 9: Checking the feature importance of each variable in Random Forest and comparing to Decision Tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4WGfZoNQDjj4"},"outputs":[],"source":["#remove ________ and print feature importance Random forest and complete the code\n","importances = rf.________________\n","\n","columns=X1.columns\n","importance_df=pd.DataFrame(importances,index=columns,columns=['Importance']).sort_values(by='Importance',ascending=False)\n","plt.figure(figsize=(8,4))\n","sns.barplot(importance_df.Importance,importance_df.index)"]},{"cell_type":"markdown","metadata":{"id":"Qb-ni3DMCMbk"},"source":["### Question 10: Comparing results of three model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPyzai3e6j6Y"},"outputs":[],"source":["print(\"Linear Regression\")\n","model_pref(model1, X_train_ols, X_test_ols,y_train,y_test)\n","print(\"Decision tree\")\n","model_pref(dt, X_train1, X_test1,y_train1,y_test1)\n","print(\"Random Forest\")\n","model_pref(rf, X_train1, X_test1,y_train1,y_test1)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}